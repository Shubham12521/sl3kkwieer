{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "#from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample document\n",
    "sample_document = \"\"\"Runing eat ate Natural language processing (NLP) is a field of artificial intelligence that focuses on the \n",
    "interaction between computers and humans using natural language.Runing eat ate\"\"\"\n",
    "\n",
    "#sentence = \"Hello I am Gayatri Deshmukh. I am from Nanded District. I will be an Engineer in few months.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Runing',\n",
       " 'eat',\n",
       " 'ate',\n",
       " 'Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'field',\n",
       " 'of',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'that',\n",
       " 'focuses',\n",
       " 'on',\n",
       " 'the',\n",
       " 'interaction',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'and',\n",
       " 'humans',\n",
       " 'using',\n",
       " 'natural',\n",
       " 'language.Runing',\n",
       " 'eat',\n",
       " 'ate']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokens = word_tokenize(sample_document)\n",
    "#print(\"Original Tokens:\", tokens)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Runing', 'VBG'),\n",
       " ('eat', 'NN'),\n",
       " ('ate', 'JJ'),\n",
       " ('Natural', 'NNP'),\n",
       " ('language', 'NN'),\n",
       " ('processing', 'NN'),\n",
       " ('(', '('),\n",
       " ('NLP', 'NNP'),\n",
       " (')', ')'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('field', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('artificial', 'JJ'),\n",
       " ('intelligence', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('focuses', 'VBZ'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('interaction', 'NN'),\n",
       " ('between', 'IN'),\n",
       " ('computers', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('humans', 'NNS'),\n",
       " ('using', 'VBG'),\n",
       " ('natural', 'JJ'),\n",
       " ('language.Runing', 'VBG'),\n",
       " ('eat', 'NN'),\n",
       " ('ate', 'NN')]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS Tagging\n",
    "pos_tags = pos_tag(tokens)\n",
    "#print(\"POS Tags:\", pos_tags)\n",
    "pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Runing',\n",
       " 'eat',\n",
       " 'ate',\n",
       " 'Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'field',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'focuses',\n",
       " 'interaction',\n",
       " 'computers',\n",
       " 'humans',\n",
       " 'using',\n",
       " 'natural',\n",
       " 'language.Runing',\n",
       " 'eat',\n",
       " 'ate']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stop Words Removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = []\n",
    "\n",
    "for word in tokens:\n",
    "    if word not in stop_words:\n",
    "        filtered_tokens.append(word)\n",
    "        \n",
    "#print(\"After Stop Words Removal:\", filtered_tokens)\n",
    "filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rune',\n",
       " 'eat',\n",
       " 'ate',\n",
       " 'natur',\n",
       " 'languag',\n",
       " 'process',\n",
       " '(',\n",
       " 'nlp',\n",
       " ')',\n",
       " 'field',\n",
       " 'artifici',\n",
       " 'intellig',\n",
       " 'focus',\n",
       " 'interact',\n",
       " 'comput',\n",
       " 'human',\n",
       " 'use',\n",
       " 'natur',\n",
       " 'language.run',\n",
       " 'eat',\n",
       " 'ate']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming\n",
    "porter_stemmer = PorterStemmer()\n",
    "stemmed_tokens = []\n",
    "\n",
    "for word in filtered_tokens:\n",
    "    stemmed=porter_stemmer.stem(word)\n",
    "    stemmed_tokens.append(stemmed)\n",
    "    \n",
    "#print(\"After Stemming:\", stemmed_tokens)\n",
    "stemmed_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Runing',\n",
       " 'eat',\n",
       " 'ate',\n",
       " 'Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'field',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'focus',\n",
       " 'interaction',\n",
       " 'computer',\n",
       " 'human',\n",
       " 'using',\n",
       " 'natural',\n",
       " 'language.Runing',\n",
       " 'eat',\n",
       " 'ate']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = []\n",
    "\n",
    "for word in filtered_tokens:\n",
    "    lemmatized=wordnet_lemmatizer.lemmatize(word)\n",
    "    lemmatized_tokens.append(lemmatized)\n",
    "\n",
    "#print(\"After Lemmatization:\", lemmatized_tokens)\n",
    "lemmatized_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create representation using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Representation: [[0.16439899 0.16439899 0.32879797 0.16439899 0.16439899 0.32879797\n",
      "  0.16439899 0.16439899 0.16439899 0.16439899 0.16439899 0.16439899\n",
      "  0.32879797 0.32879797 0.16439899 0.16439899 0.16439899 0.16439899\n",
      "  0.32879797 0.16439899 0.16439899 0.16439899]]\n",
      "\n",
      "Feature Names: ['and' 'artificial' 'ate' 'between' 'computers' 'eat' 'field' 'focuses'\n",
      " 'humans' 'intelligence' 'interaction' 'is' 'language' 'natural' 'nlp'\n",
      " 'of' 'on' 'processing' 'runing' 'that' 'the' 'using']\n"
     ]
    }
   ],
   "source": [
    "documents = [sample_document]\n",
    "\n",
    "# create object\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# get tf-df values\n",
    "result = tfidf.fit_transform(documents)\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "print(\"\\nTF-IDF Representation:\",result.toarray())\n",
    "print(\"\\nFeature Names:\", feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
